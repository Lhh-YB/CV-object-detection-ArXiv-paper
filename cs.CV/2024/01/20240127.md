# Arxiv Papers in cs.CV on 2024-01-27
### You Only Look Bottom-Up for Monocular 3D Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2401.15319v1
- **DOI**: 10.1109/LRA.2023.3313053
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2401.15319v1)
- **Published**: 2024-01-27 06:45:35+00:00
- **Updated**: 2024-01-27 06:45:35+00:00
- **Authors**: Kaixin Xiong, Dingyuan Zhang, Dingkang Liang, Zhe Liu, Hongcheng Yang, Wondimu Dikubab, Jianwei Cheng, Xiang Bai
- **Comment**: Accepted by IEEE Robotics and Automation Letters (RA-L)
- **Journal**: None
- **Summary**: Monocular 3D Object Detection is an essential task for autonomous driving. Meanwhile, accurate 3D object detection from pure images is very challenging due to the loss of depth information. Most existing image-based methods infer objects' location in 3D space based on their 2D sizes on the image plane, which usually ignores the intrinsic position clues from images, leading to unsatisfactory performances. Motivated by the fact that humans could leverage the bottom-up positional clues to locate objects in 3D space from a single image, in this paper, we explore the position modeling from the image feature column and propose a new method named You Only Look Bottum-Up (YOLOBU). Specifically, our YOLOBU leverages Column-based Cross Attention to determine how much a pixel contributes to pixels above it. Next, the Row-based Reverse Cumulative Sum (RRCS) is introduced to build the connections of pixels in the bottom-up direction. Our YOLOBU fully explores the position clues for monocular 3D detection via building the relationship of pixels from the bottom-up way. Extensive experiments on the KITTI dataset demonstrate the effectiveness and superiority of our method.



### New Foggy Object Detecting Model
- **Arxiv ID**: http://arxiv.org/abs/2401.15455v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2401.15455v1)
- **Published**: 2024-01-27 16:29:53+00:00
- **Updated**: 2024-01-27 16:29:53+00:00
- **Authors**: Rahul Banavathu, Modem Veda Sree, Bollina Kavya Sri, Suddhasil De
- **Comment**: None
- **Journal**: None
- **Summary**: Object detection in reduced visibility has become a prominent research area. The existing techniques are not accurate enough in recognizing objects under such circumstances. This paper introduces a new foggy object detection method through a two-staged architecture of region identification from input images and detecting objects in such regions. The paper confirms notable improvements of the proposed method's accuracy and detection time over existing techniques.



