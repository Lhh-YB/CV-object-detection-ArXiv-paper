# Arxiv Papers in cs.CV on 2024-11-07
### UEVAVD: A Dataset for Developing UAV's Eye View Active Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2411.04348v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2411.04348v1)
- **Published**: 2024-11-07 01:10:05+00:00
- **Updated**: 2024-11-07 01:10:05+00:00
- **Authors**: Xinhua Jiang, Tianpeng Liu, Li Liu, Zhen Liu, Yongxiang Liu
- **Comment**: None
- **Journal**: None
- **Summary**: Occlusion is a longstanding difficulty that challenges the UAV-based object detection. Many works address this problem by adapting the detection model. However, few of them exploit that the UAV could fundamentally improve detection performance by changing its viewpoint. Active Object Detection (AOD) offers an effective way to achieve this purpose. Through Deep Reinforcement Learning (DRL), AOD endows the UAV with the ability of autonomous path planning to search for the observation that is more conducive to target identification. Unfortunately, there exists no available dataset for developing the UAV AOD method. To fill this gap, we released a UAV's eye view active vision dataset named UEVAVD and hope it can facilitate research on the UAV AOD problem. Additionally, we improve the existing DRL-based AOD method by incorporating the inductive bias when learning the state representation. First, due to the partial observability, we use the gated recurrent unit to extract state representations from the observation sequence instead of the single-view observation. Second, we pre-decompose the scene with the Segment Anything Model (SAM) and filter out the irrelevant information with the derived masks. With these practices, the agent could learn an active viewing policy with better generalization capability. The effectiveness of our innovations is validated by the experiments on the UEVAVD dataset. Our dataset will soon be available at https://github.com/Leo000ooo/UEVAVD_dataset.



### On the Inherent Robustness of One-Stage Object Detection against Out-of-Distribution Data
- **Arxiv ID**: http://arxiv.org/abs/2411.04586v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG, 68T45, 68T07, I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/2411.04586v1)
- **Published**: 2024-11-07 10:15:25+00:00
- **Updated**: 2024-11-07 10:15:25+00:00
- **Authors**: Aitor Martinez-Seras, Javier Del Ser, Alain Andres, Pablo Garcia-Bringas
- **Comment**: 12 figures, 4 tables, under review
- **Journal**: None
- **Summary**: Robustness is a fundamental aspect for developing safe and trustworthy models, particularly when they are deployed in the open world. In this work we analyze the inherent capability of one-stage object detectors to robustly operate in the presence of out-of-distribution (OoD) data. Specifically, we propose a novel detection algorithm for detecting unknown objects in image data, which leverages the features extracted by the model from each sample. Differently from other recent approaches in the literature, our proposal does not require retraining the object detector, thereby allowing for the use of pretrained models. Our proposed OoD detector exploits the application of supervised dimensionality reduction techniques to mitigate the effects of the curse of dimensionality on the features extracted by the model. Furthermore, it utilizes high-resolution feature maps to identify potential unknown objects in an unsupervised fashion. Our experiments analyze the Pareto trade-off between the performance detecting known and unknown objects resulting from different algorithmic configurations and inference confidence thresholds. We also compare the performance of our proposed algorithm to that of logits-based post-hoc OoD methods, as well as possible fusion strategies. Finally, we discuss on the competitiveness of all tested methods against state-of-the-art OoD approaches for object detection models over the recently published Unknown Object Detection benchmark. The obtained results verify that the performance of avant-garde post-hoc OoD detectors can be further improved when combined with our proposed algorithm.



### Exploring the Feasibility of Affordable Sonar Technology: Object Detection in Underwater Environments Using the Ping 360
- **Arxiv ID**: http://arxiv.org/abs/2411.05863v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.ET
- **Links**: [PDF](http://arxiv.org/pdf/2411.05863v1)
- **Published**: 2024-11-07 11:50:40+00:00
- **Updated**: 2024-11-07 11:50:40+00:00
- **Authors**: Md Junayed Hasan, Somasundar Kannan, Ali Rohan, Mohd Asif Shah
- **Comment**: This work is currently under review. This is a pre-print
- **Journal**: None
- **Summary**: This study explores the potential of the Ping 360 sonar device, primarily used for navigation, in detecting complex underwater obstacles. The key motivation behind this research is the device's affordability and open-source nature, offering a cost-effective alternative to more expensive imaging sonar systems. The investigation focuses on understanding the behaviour of the Ping 360 in controlled environments and assessing its suitability for object detection, particularly in scenarios where human operators are unavailable for inspecting offshore structures in shallow waters. Through a series of carefully designed experiments, we examined the effects of surface reflections and object shadows in shallow underwater environments. Additionally, we developed a manually annotated sonar image dataset to train a U-Net segmentation model. Our findings indicate that while the Ping 360 sonar demonstrates potential in simpler settings, its performance is limited in more cluttered or reflective environments unless extensive data pre-processing and annotation are applied. To our knowledge, this is the first study to evaluate the Ping 360's capabilities for complex object detection. By investigating the feasibility of low-cost sonar devices, this research provides valuable insights into their limitations and potential for future AI-based interpretation, marking a unique contribution to the field.



