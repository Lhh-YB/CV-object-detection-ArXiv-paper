# Arxiv Papers in cs.CV on 2024-02-03
### Multimodal-Enhanced Objectness Learner for Corner Case Detection in Autonomous Driving
- **Arxiv ID**: http://arxiv.org/abs/2402.02026v2
- **DOI**: 10.1109/ICIP51287.2024.10647363
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2402.02026v2)
- **Published**: 2024-02-03 04:47:03+00:00
- **Updated**: 2024-09-28 08:40:14+00:00
- **Authors**: Lixing Xiao, Ruixiao Shi, Xiaoyang Tang, Yi Zhou
- **Comment**: Accepted to 2024 IEEE International Conference on Image Processing
  (ICIP) as oral presentation
- **Journal**: None
- **Summary**: Previous works on object detection have achieved high accuracy in closed-set scenarios, but their performance in open-world scenarios is not satisfactory. One of the challenging open-world problems is corner case detection in autonomous driving. Existing detectors struggle with these cases, relying heavily on visual appearance and exhibiting poor generalization ability. In this paper, we propose a solution by reducing the discrepancy between known and unknown classes and introduce a multimodal-enhanced objectness notion learner. Leveraging both vision-centric and image-text modalities, our semi-supervised learning framework imparts objectness knowledge to the student model, enabling class-aware detection. Our approach, Multimodal-Enhanced Objectness Learner (MENOL) for Corner Case Detection, significantly improves recall for novel classes with lower training costs. By achieving a 76.6% mAR-corner and 79.8% mAR-agnostic on the CODA-val dataset with just 5100 labeled training images, MENOL outperforms the baseline ORE by 71.3% and 60.6%, respectively. The code will be available at https://github.com/tryhiseyyysum/MENOL.



### CoFiNet: Unveiling Camouflaged Objects with Multi-Scale Finesse
- **Arxiv ID**: http://arxiv.org/abs/2402.02217v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2402.02217v1)
- **Published**: 2024-02-03 17:24:55+00:00
- **Updated**: 2024-02-03 17:24:55+00:00
- **Authors**: Cunhan Guo, Heyan Huang
- **Comment**: None
- **Journal**: None
- **Summary**: Camouflaged Object Detection (COD) is a critical aspect of computer vision aimed at identifying concealed objects, with applications spanning military, industrial, medical and monitoring domains. To address the problem of poor detail segmentation effect, we introduce a novel method for camouflage object detection, named CoFiNet. Our approach primarily focuses on multi-scale feature fusion and extraction, with special attention to the model's segmentation effectiveness for detailed features, enhancing its ability to effectively detect camouflaged objects. CoFiNet adopts a coarse-to-fine strategy. A multi-scale feature integration module is laveraged to enhance the model's capability of fusing context feature. A multi-activation selective kernel module is leveraged to grant the model the ability to autonomously alter its receptive field, enabling it to selectively choose an appropriate receptive field for camouflaged objects of different sizes. During mask generation, we employ the dual-mask strategy for image segmentation, separating the reconstruction of coarse and fine masks, which significantly enhances the model's learning capacity for details. Comprehensive experiments were conducted on four different datasets, demonstrating that CoFiNet achieves state-of-the-art performance across all datasets. The experiment results of CoFiNet underscore its effectiveness in camouflage object detection and highlight its potential in various practical application scenarios.



