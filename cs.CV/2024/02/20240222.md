# Arxiv Papers in cs.CV on 2024-02-22
### YOLO-TLA: An Efficient and Lightweight Small Object Detection Model based on YOLOv5
- **Arxiv ID**: http://arxiv.org/abs/2402.14309v2
- **DOI**: 10.1007/s11554-024-01519-4
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2402.14309v2)
- **Published**: 2024-02-22 05:55:17+00:00
- **Updated**: 2024-07-29 01:48:25+00:00
- **Authors**: Chun-Lin Ji, Tao Yu, Peng Gao, Fei Wang, Ru-Yue Yuan
- **Comment**: None
- **Journal**: None
- **Summary**: Object detection, a crucial aspect of computer vision, has seen significant advancements in accuracy and robustness. Despite these advancements, practical applications still face notable challenges, primarily the inaccurate detection or missed detection of small objects. In this paper, we propose YOLO-TLA, an advanced object detection model building on YOLOv5. We first introduce an additional detection layer for small objects in the neck network pyramid architecture, thereby producing a feature map of a larger scale to discern finer features of small objects. Further, we integrate the C3CrossCovn module into the backbone network. This module uses sliding window feature extraction, which effectively minimizes both computational demand and the number of parameters, rendering the model more compact. Additionally, we have incorporated a global attention mechanism into the backbone network. This mechanism combines the channel information with global information to create a weighted feature map. This feature map is tailored to highlight the attributes of the object of interest, while effectively ignoring irrelevant details. In comparison to the baseline YOLOv5s model, our newly developed YOLO-TLA model has shown considerable improvements on the MS COCO validation dataset, with increases of 4.6% in mAP@0.5 and 4% in mAP@0.5:0.95, all while keeping the model size compact at 9.49M parameters. Further extending these improvements to the YOLOv5m model, the enhanced version exhibited a 1.7% and 1.9% increase in mAP@0.5 and mAP@0.5:0.95, respectively, with a total of 27.53M parameters. These results validate the YOLO-TLA model's efficient and effective performance in small object detection, achieving high accuracy with fewer parameters and computational demands.



### Reading Relevant Feature from Global Representation Memory for Visual Object Tracking
- **Arxiv ID**: http://arxiv.org/abs/2402.14392v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2402.14392v3)
- **Published**: 2024-02-22 09:07:04+00:00
- **Updated**: 2024-02-26 23:13:32+00:00
- **Authors**: Xinyu Zhou, Pinxue Guo, Lingyi Hong, Jinglun Li, Wei Zhang, Weifeng Ge, Wenqiang Zhang
- **Comment**: 9pages,5 figures, accepted by the Thirty-seventh Conference on Neural
  Information Processing Systems(Neurips 2023)
- **Journal**: None
- **Summary**: Reference features from a template or historical frames are crucial for visual object tracking. Prior works utilize all features from a fixed template or memory for visual object tracking. However, due to the dynamic nature of videos, the required reference historical information for different search regions at different time steps is also inconsistent. Therefore, using all features in the template and memory can lead to redundancy and impair tracking performance. To alleviate this issue, we propose a novel tracking paradigm, consisting of a relevance attention mechanism and a global representation memory, which can adaptively assist the search region in selecting the most relevant historical information from reference features. Specifically, the proposed relevance attention mechanism in this work differs from previous approaches in that it can dynamically choose and build the optimal global representation memory for the current frame by accessing cross-frame information globally. Moreover, it can flexibly read the relevant historical information from the constructed memory to reduce redundancy and counteract the negative effects of harmful information. Extensive experiments validate the effectiveness of the proposed method, achieving competitive performance on five challenging datasets with 71 FPS.



### GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion
- **Arxiv ID**: http://arxiv.org/abs/2402.14810v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.GR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2402.14810v1)
- **Published**: 2024-02-22 18:59:21+00:00
- **Updated**: 2024-02-22 18:59:21+00:00
- **Authors**: Xueyi Liu, Li Yi
- **Comment**: Accepted to ICLR 2024. Project website:
  https://meowuu7.github.io/GeneOH-Diffusion/; Huggingface Demo:
  https://huggingface.co/spaces/xymeow7/gene-hoi-denoising; Code:
  https://github.com/Meowuu7/GeneOH-Diffusion
- **Journal**: ICLR 2024
- **Summary**: In this work, we tackle the challenging problem of denoising hand-object interactions (HOI). Given an erroneous interaction sequence, the objective is to refine the incorrect hand trajectory to remove interaction artifacts for a perceptually realistic sequence. This challenge involves intricate interaction noise, including unnatural hand poses and incorrect hand-object relations, alongside the necessity for robust generalization to new interactions and diverse noise patterns. We tackle those challenges through a novel approach, GeneOH Diffusion, incorporating two key designs: an innovative contact-centric HOI representation named GeneOH and a new domain-generalizable denoising scheme. The contact-centric representation GeneOH informatively parameterizes the HOI process, facilitating enhanced generalization across various HOI scenarios. The new denoising scheme consists of a canonical denoising model trained to project noisy data samples from a whitened noise space to a clean data manifold and a "denoising via diffusion" strategy which can handle input trajectories with various noise patterns by first diffusing them to align with the whitened noise space and cleaning via the canonical denoiser. Extensive experiments on four benchmarks with significant domain variations demonstrate the superior effectiveness of our method. GeneOH Diffusion also shows promise for various downstream applications. Project website: https://meowuu7.github.io/GeneOH-Diffusion/.



