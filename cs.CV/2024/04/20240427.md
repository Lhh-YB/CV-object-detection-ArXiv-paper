# Arxiv Papers in cs.CV on 2024-04-27
### BoostRad: Enhancing Object Detection by Boosting Radar Reflections
- **Arxiv ID**: http://arxiv.org/abs/2404.17861v1
- **DOI**: 10.1109/WACV57701.2024.00166
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2404.17861v1)
- **Published**: 2024-04-27 10:40:52+00:00
- **Updated**: 2024-04-27 10:40:52+00:00
- **Authors**: Yuval Haitman, Oded Bialer
- **Comment**: WACV2024
- **Journal**: 2024 IEEE/CVF Winter Conference on Applications of Computer Vision
  (WACV), Waikoloa, HI, USA, 2024, pp. 1627-1636
- **Summary**: Automotive radars have an important role in autonomous driving systems. The main challenge in automotive radar detection is the radar's wide point spread function (PSF) in the angular domain that causes blurriness and clutter in the radar image. Numerous studies suggest employing an 'end-to-end' learning strategy using a Deep Neural Network (DNN) to directly detect objects from radar images. This approach implicitly addresses the PSF's impact on objects of interest. In this paper, we propose an alternative approach, which we term "Boosting Radar Reflections" (BoostRad). In BoostRad, a first DNN is trained to narrow the PSF for all the reflection points in the scene. The output of the first DNN is a boosted reflection image with higher resolution and reduced clutter, resulting in a sharper and cleaner image. Subsequently, a second DNN is employed to detect objects within the boosted reflection image. We develop a novel method for training the boosting DNN that incorporates domain knowledge of radar's PSF characteristics. BoostRad's performance is evaluated using the RADDet and CARRADA datasets, revealing its superiority over reference methods.



### Reliable Student: Addressing Noise in Semi-Supervised 3D Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2404.17910v1
- **DOI**: 10.1109/CVPRW59228.2023.00526
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2404.17910v1)
- **Published**: 2024-04-27 13:38:45+00:00
- **Updated**: 2024-04-27 13:38:45+00:00
- **Authors**: Farzad Nozarian, Shashank Agarwal, Farzaneh Rezaeianaran, Danish Shahzad, Atanas Poibrenski, Christian MÃ¼ller, Philipp Slusallek
- **Comment**: Accepted at CVPR Workshop L3D-IVU 2023. Code:
  https://github.com/fnozarian/ReliableStudent
- **Journal**: None
- **Summary**: Semi-supervised 3D object detection can benefit from the promising pseudo-labeling technique when labeled data is limited. However, recent approaches have overlooked the impact of noisy pseudo-labels during training, despite efforts to enhance pseudo-label quality through confidence-based filtering. In this paper, we examine the impact of noisy pseudo-labels on IoU-based target assignment and propose the Reliable Student framework, which incorporates two complementary approaches to mitigate errors. First, it involves a class-aware target assignment strategy that reduces false negative assignments in difficult classes. Second, it includes a reliability weighting strategy that suppresses false positive assignment errors while also addressing remaining false negatives from the first step. The reliability weights are determined by querying the teacher network for confidence scores of the student-generated proposals. Our work surpasses the previous state-of-the-art on KITTI 3D object detection benchmark on point clouds in the semi-supervised setting. On 1% labeled data, our approach achieves a 6.2% AP improvement for the pedestrian class, despite having only 37 labeled samples available. The improvements become significant for the 2% setting, achieving 6.0% AP and 5.7% AP improvements for the pedestrian and cyclist classes, respectively.



### Retrieval Robust to Object Motion Blur
- **Arxiv ID**: http://arxiv.org/abs/2404.18025v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2404.18025v2)
- **Published**: 2024-04-27 23:22:39+00:00
- **Updated**: 2024-07-17 21:57:16+00:00
- **Authors**: Rong Zou, Marc Pollefeys, Denys Rozumnyi
- **Comment**: None
- **Journal**: None
- **Summary**: Moving objects are frequently seen in daily life and usually appear blurred in images due to their motion. While general object retrieval is a widely explored area in computer vision, it primarily focuses on sharp and static objects, and retrieval of motion-blurred objects in large image collections remains unexplored. We propose a method for object retrieval in images that are affected by motion blur. The proposed method learns a robust representation capable of matching blurred objects to their deblurred versions and vice versa. To evaluate our approach, we present the first large-scale datasets for blurred object retrieval, featuring images with objects exhibiting varying degrees of blur in various poses and scales. We conducted extensive experiments, showing that our method outperforms state-of-the-art retrieval methods on the new blur-retrieval datasets, which validates the effectiveness of the proposed approach. Code, data, and model are available at https://github.com/Rong-Zou/Retrieval-Robust-to-Object-Motion-Blur.



