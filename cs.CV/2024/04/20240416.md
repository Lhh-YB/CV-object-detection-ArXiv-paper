# Arxiv Papers in cs.CV on 2024-04-16
### OSR-ViT: A Simple and Modular Framework for Open-Set Object Detection and Discovery
- **Arxiv ID**: http://arxiv.org/abs/2404.10865v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2404.10865v1)
- **Published**: 2024-04-16 19:29:27+00:00
- **Updated**: 2024-04-16 19:29:27+00:00
- **Authors**: Matthew Inkawhich, Nathan Inkawhich, Hao Yang, Jingyang Zhang, Randolph Linderman, Yiran Chen
- **Comment**: 28 pages, 8 figures, 7 tables
- **Journal**: None
- **Summary**: An object detector's ability to detect and flag \textit{novel} objects during open-world deployments is critical for many real-world applications. Unfortunately, much of the work in open object detection today is disjointed and fails to adequately address applications that prioritize unknown object recall \textit{in addition to} known-class accuracy. To close this gap, we present a new task called Open-Set Object Detection and Discovery (OSODD) and as a solution propose the Open-Set Regions with ViT features (OSR-ViT) detection framework. OSR-ViT combines a class-agnostic proposal network with a powerful ViT-based classifier. Its modular design simplifies optimization and allows users to easily swap proposal solutions and feature extractors to best suit their application. Using our multifaceted evaluation protocol, we show that OSR-ViT obtains performance levels that far exceed state-of-the-art supervised methods. Our method also excels in low-data settings, outperforming supervised baselines using a fraction of the training data.



