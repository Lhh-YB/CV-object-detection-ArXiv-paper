# Arxiv Papers in cs.CV on 2024-08-06
### Diverse Generation while Maintaining Semantic Coordination: A Diffusion-Based Data Augmentation Method for Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2408.02891v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2408.02891v1)
- **Published**: 2024-08-06 01:41:40+00:00
- **Updated**: 2024-08-06 01:41:40+00:00
- **Authors**: Sen Nie, Zhuo Wang, Xinxin Wang, Kun He
- **Comment**: 15 pages, 7 figures, ICPR2024
- **Journal**: None
- **Summary**: Recent studies emphasize the crucial role of data augmentation in enhancing the performance of object detection models. However,existing methodologies often struggle to effectively harmonize dataset diversity with semantic coordination.To bridge this gap, we introduce an innovative augmentation technique leveraging pre-trained conditional diffusion models to mediate this balance. Our approach encompasses the development of a Category Affinity Matrix, meticulously designed to enhance dataset diversity, and a Surrounding Region Alignment strategy, which ensures the preservation of semantic coordination in the augmented images. Extensive experimental evaluations confirm the efficacy of our method in enriching dataset diversity while seamlessly maintaining semantic coordination. Our method yields substantial average improvements of +1.4AP, +0.9AP, and +3.4AP over existing alternatives on three distinct object detection models, respectively.



### An Object is Worth 64x64 Pixels: Generating 3D Object via Image Diffusion
- **Arxiv ID**: http://arxiv.org/abs/2408.03178v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2408.03178v1)
- **Published**: 2024-08-06 13:22:51+00:00
- **Updated**: 2024-08-06 13:22:51+00:00
- **Authors**: Xingguang Yan, Han-Hung Lee, Ziyu Wan, Angel X. Chang
- **Comment**: Project Page: https://omages.github.io/
- **Journal**: None
- **Summary**: We introduce a new approach for generating realistic 3D models with UV maps through a representation termed "Object Images." This approach encapsulates surface geometry, appearance, and patch structures within a 64x64 pixel image, effectively converting complex 3D shapes into a more manageable 2D format. By doing so, we address the challenges of both geometric and semantic irregularity inherent in polygonal meshes. This method allows us to use image generation models, such as Diffusion Transformers, directly for 3D shape generation. Evaluated on the ABO dataset, our generated shapes with patch structures achieve point cloud FID comparable to recent 3D generative models, while naturally supporting PBR material generation.



### Line-based 6-DoF Object Pose Estimation and Tracking With an Event Camera
- **Arxiv ID**: http://arxiv.org/abs/2408.03225v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2408.03225v1)
- **Published**: 2024-08-06 14:36:43+00:00
- **Updated**: 2024-08-06 14:36:43+00:00
- **Authors**: Zibin Liu, Banglei Guan, Yang Shang, Qifeng Yu, Laurent Kneip
- **Comment**: Accepted by IEEE Transactions on Image Processing,2024
- **Journal**: None
- **Summary**: Pose estimation and tracking of objects is a fundamental application in 3D vision. Event cameras possess remarkable attributes such as high dynamic range, low latency, and resilience against motion blur, which enables them to address challenging high dynamic range scenes or high-speed motion. These features make event cameras an ideal complement over standard cameras for object pose estimation. In this work, we propose a line-based robust pose estimation and tracking method for planar or non-planar objects using an event camera. Firstly, we extract object lines directly from events, then provide an initial pose using a globally-optimal Branch-and-Bound approach, where 2D-3D line correspondences are not known in advance. Subsequently, we utilize event-line matching to establish correspondences between 2D events and 3D models. Furthermore, object poses are refined and continuously tracked by minimizing event-line distances. Events are assigned different weights based on these distances, employing robust estimation algorithms. To evaluate the precision of the proposed methods in object pose estimation and tracking, we have devised and established an event-based moving object dataset. Compared against state-of-the-art methods, the robustness and accuracy of our methods have been validated both on synthetic experiments and the proposed dataset. The source code is available at https://github.com/Zibin6/LOPET.



### Biomedical Image Segmentation: A Systematic Literature Review of Deep Learning Based Object Detection Methods
- **Arxiv ID**: http://arxiv.org/abs/2408.03393v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/2408.03393v2)
- **Published**: 2024-08-06 18:38:55+00:00
- **Updated**: 2024-08-28 19:56:19+00:00
- **Authors**: Fazli Wahid, Yingliang Ma, Dawar Khan, Muhammad Aamir, Syed U. K. Bukhari
- **Comment**: None
- **Journal**: None
- **Summary**: Biomedical image segmentation plays a vital role in diagnosis of diseases across various organs. Deep learning-based object detection methods are commonly used for such segmentation. There exists an extensive research in this topic. However, there is no standard review on this topic. Existing surveys often lack a standardized approach or focus on broader segmentation techniques. In this paper, we conducted a systematic literature review (SLR), collected and analysed 148 articles that explore deep learning object detection methods for biomedical image segmentation. We critically analyzed these methods, identified the key challenges, and discussed the future directions. From the selected articles we extracted the results including the deep learning models, targeted imaging modalities, targeted diseases, and the metrics for the analysis of the methods. The results have been presented in tabular and/or charted forms. The results are presented in three major categories including two stage detection models, one stage detection models and point-based detection models. Each article is individually analyzed along with its pros and cons. Finally, we discuss open challenges, potential benefits, and future research directions. This SLR aims to provide the research community with a quick yet deeper understanding of these segmentation models, ultimately facilitating the development of more powerful solutions for biomedical image analysis.



