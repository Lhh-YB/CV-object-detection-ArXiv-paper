# Arxiv Papers in cs.CV on 2024-08-10
### Object Re-identification via Spatial-temporal Fusion Networks and Causal Identity Matching
- **Arxiv ID**: http://arxiv.org/abs/2408.05558v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2408.05558v2)
- **Published**: 2024-08-10 13:50:43+00:00
- **Updated**: 2024-08-22 11:25:31+00:00
- **Authors**: Hye-Geun Kim, Yong-Hyuk Moon, Yeong-Jun Cho
- **Comment**: None
- **Journal**: None
- **Summary**: Object re-identification (ReID) in large camera networks faces numerous challenges. First, the similar appearances of objects degrade ReID performance, a challenge that needs to be addressed by existing appearance-based ReID methods. Second, most ReID studies are performed in laboratory settings and do not consider real-world scenarios. To overcome these challenges, we introduce a novel ReID framework that leverages a spatial-temporal fusion network and causal identity matching (CIM). Our framework estimates camera network topology using a proposed adaptive Parzen window and combines appearance features with spatial-temporal cues within the fusion network. This approach has demonstrated outstanding performance across several datasets, including VeRi776, Vehicle-3I, and Market-1501, achieving up to 99.70% rank-1 accuracy and 95.5% mAP. Furthermore, the proposed CIM approach, which dynamically assigns gallery sets based on camera network topology, has further improved ReID accuracy and robustness in real-world settings, evidenced by a 94.95% mAP and a 95.19% F1 score on the Vehicle-3I dataset. The experimental results support the effectiveness of incorporating spatial-temporal information and CIM for real-world ReID scenarios, regardless of the data domain (e.g., vehicle, person).



