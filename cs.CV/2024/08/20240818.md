# Arxiv Papers in cs.CV on 2024-08-18
### YOLOv1 to YOLOv10: The fastest and most accurate real-time object detection systems
- **Arxiv ID**: http://arxiv.org/abs/2408.09332v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2408.09332v1)
- **Published**: 2024-08-18 02:11:00+00:00
- **Updated**: 2024-08-18 02:11:00+00:00
- **Authors**: Chien-Yao Wang, Hong-Yuan Mark Liao
- **Comment**: 13 pages, 14 figures
- **Journal**: None
- **Summary**: This is a comprehensive review of the YOLO series of systems. Different from previous literature surveys, this review article re-examines the characteristics of the YOLO series from the latest technical point of view. At the same time, we also analyzed how the YOLO series continued to influence and promote real-time computer vision-related research and led to the subsequent development of computer vision and language models.We take a closer look at how the methods proposed by the YOLO series in the past ten years have affected the development of subsequent technologies and show the applications of YOLO in various fields. We hope this article can play a good guiding role in subsequent real-time computer vision development.



### Adversarial Attacked Teacher for Unsupervised Domain Adaptive Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2408.09431v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2408.09431v1)
- **Published**: 2024-08-18 10:22:23+00:00
- **Updated**: 2024-08-18 10:22:23+00:00
- **Authors**: Kaiwen Wang, Yinzhe Shen, Martin Lauer
- **Comment**: None
- **Journal**: None
- **Summary**: Object detectors encounter challenges in handling domain shifts. Cutting-edge domain adaptive object detection methods use the teacher-student framework and domain adversarial learning to generate domain-invariant pseudo-labels for self-training. However, the pseudo-labels generated by the teacher model tend to be biased towards the majority class and often mistakenly include overconfident false positives and underconfident false negatives. We reveal that pseudo-labels vulnerable to adversarial attacks are more likely to be low-quality. To address this, we propose a simple yet effective framework named Adversarial Attacked Teacher (AAT) to improve the quality of pseudo-labels. Specifically, we apply adversarial attacks to the teacher model, prompting it to generate adversarial pseudo-labels to correct bias, suppress overconfidence, and encourage underconfident proposals. An adaptive pseudo-label regularization is introduced to emphasize the influence of pseudo-labels with high certainty and reduce the negative impacts of uncertain predictions. Moreover, robust minority objects verified by pseudo-label regularization are oversampled to minimize dataset imbalance without introducing false positives. Extensive experiments conducted on various datasets demonstrate that AAT achieves superior performance, reaching 52.6 mAP on Clipart1k, surpassing the previous state-of-the-art by 6.7%.



### Retina-Inspired Object Motion Segmentation for Event-Cameras
- **Arxiv ID**: http://arxiv.org/abs/2408.09454v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2408.09454v2)
- **Published**: 2024-08-18 12:28:26+00:00
- **Updated**: 2024-12-06 12:37:08+00:00
- **Authors**: Victoria Clerico, Shay Snyder, Arya Lohia, Md Abdullah-Al Kaiser, Gregory Schwartz, Akhilesh Jaiswal, Maryam Parsa
- **Comment**: None
- **Journal**: None
- **Summary**: Event-cameras have emerged as a revolutionary technology with a high temporal resolution that far surpasses standard active pixel cameras. This technology draws biological inspiration from photoreceptors and the initial retinal synapse. This research showcases the potential of additional retinal functionalities to extract visual features. We provide a domain-agnostic and efficient algorithm for ego-motion compensation based on Object Motion Sensitivity (OMS), one of the multiple features computed within the mammalian retina. We develop a method based on experimental neuroscience that translates OMS' biological circuitry to a low-overhead algorithm to suppress camera motion bypassing the need for deep networks and learning. Our system processes event data from dynamic scenes to perform pixel-wise object motion segmentation using a real and synthetic dataset. This paper introduces a bio-inspired computer vision method that dramatically reduces the number of parameters by $\text{10}^\text{3}$ to $\text{10}^\text{6}$ orders of magnitude compared to previous approaches. Our work paves the way for robust, high-speed, and low-bandwidth decision-making for in-sensor computations.



