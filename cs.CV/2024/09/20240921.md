# Arxiv Papers in cs.CV on 2024-09-21
### CUS3D :CLIP-based Unsupervised 3D Segmentation via Object-level Denoise
- **Arxiv ID**: http://arxiv.org/abs/2409.13982v1
- **DOI**: 10.1109/ICME57554.2024
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2409.13982v1)
- **Published**: 2024-09-21 02:17:35+00:00
- **Updated**: 2024-09-21 02:17:35+00:00
- **Authors**: Fuyang Yu, Runze Tian, Zhen Wang, Xiaochuan Wang, Xiaohui Liang
- **Comment**: 6 pages,3 figures
- **Journal**: None
- **Summary**: To ease the difficulty of acquiring annotation labels in 3D data, a common method is using unsupervised and open-vocabulary semantic segmentation, which leverage 2D CLIP semantic knowledge. In this paper, unlike previous research that ignores the ``noise'' raised during feature projection from 2D to 3D, we propose a novel distillation learning framework named CUS3D. In our approach, an object-level denosing projection module is designed to screen out the ``noise'' and ensure more accurate 3D feature. Based on the obtained features, a multimodal distillation learning module is designed to align the 3D feature with CLIP semantic feature space with object-centered constrains to achieve advanced unsupervised semantic segmentation. We conduct comprehensive experiments in both unsupervised and open-vocabulary segmentation, and the results consistently showcase the superiority of our model in achieving advanced unsupervised segmentation results and its effectiveness in open-vocabulary segmentation.



### Dynamic 2D Gaussians: Geometrically accurate radiance fields for dynamic objects
- **Arxiv ID**: http://arxiv.org/abs/2409.14072v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2409.14072v1)
- **Published**: 2024-09-21 09:01:49+00:00
- **Updated**: 2024-09-21 09:01:49+00:00
- **Authors**: Shuai Zhang, Guanjun Wu, Xinggang Wang, Bin Feng, Wenyu Liu
- **Comment**: None
- **Journal**: None
- **Summary**: Reconstructing objects and extracting high-quality surfaces play a vital role in the real world. Current 4D representations show the ability to render high-quality novel views for dynamic objects but cannot reconstruct high-quality meshes due to their implicit or geometrically inaccurate representations. In this paper, we propose a novel representation that can reconstruct accurate meshes from sparse image input, named Dynamic 2D Gaussians (D-2DGS). We adopt 2D Gaussians for basic geometry representation and use sparse-controlled points to capture 2D Gaussian's deformation. By extracting the object mask from the rendered high-quality image and masking the rendered depth map, a high-quality dynamic mesh sequence of the object can be extracted. Experiments demonstrate that our D-2DGS is outstanding in reconstructing high-quality meshes from sparse input. More demos and code are available at https://github.com/hustvl/Dynamic-2DGS.



### Temporally Propagated Masks and Bounding Boxes: Combining the Best of Both Worlds for Multi-Object Tracking
- **Arxiv ID**: http://arxiv.org/abs/2409.14220v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2409.14220v3)
- **Published**: 2024-09-21 18:52:07+00:00
- **Updated**: 2024-11-22 21:32:53+00:00
- **Authors**: Tomasz Stanczyk, Francois Bremond
- **Comment**: None
- **Journal**: None
- **Summary**: Multi-object tracking (MOT) involves identifying and consistently tracking objects across video sequences. Traditional tracking-by-detection methods, while effective, often require extensive tuning and lack generalizability. On the other hand, segmentation mask-based methods are more generic but struggle with tracking management, making them unsuitable for MOT. We propose a novel approach, McByte, which incorporates a temporally propagated segmentation mask as a strong association cue within a tracking-by-detection framework. By combining bounding box and propagated mask information, McByte enhances robustness and generalizability without per-sequence tuning. Evaluated on four benchmark datasets - DanceTrack, MOT17, SoccerNet-tracking 2022, and KITTI-tracking - McByte demonstrates performance gain in all cases examined. At the same time, it outperforms existing mask-based methods. Implementation code will be provided upon acceptance.



