# Arxiv Papers in cs.CV on 2024-07-26
### Rapid Object Annotation
- **Arxiv ID**: http://arxiv.org/abs/2407.18682v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2407.18682v1)
- **Published**: 2024-07-26 11:56:23+00:00
- **Updated**: 2024-07-26 11:56:23+00:00
- **Authors**: Misha Denil
- **Comment**: None
- **Journal**: None
- **Summary**: In this report we consider the problem of rapidly annotating a video with bounding boxes for a novel object. We describe a UI and associated workflow designed to make this process fast for an arbitrary novel target.



### Floating No More: Object-Ground Reconstruction from a Single Image
- **Arxiv ID**: http://arxiv.org/abs/2407.18914v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2407.18914v1)
- **Published**: 2024-07-26 17:59:56+00:00
- **Updated**: 2024-07-26 17:59:56+00:00
- **Authors**: Yunze Man, Yichen Sheng, Jianming Zhang, Liang-Yan Gui, Yu-Xiong Wang
- **Comment**: Project Page: https://yunzeman.github.io/ORG/
- **Journal**: None
- **Summary**: Recent advancements in 3D object reconstruction from single images have primarily focused on improving the accuracy of object shapes. Yet, these techniques often fail to accurately capture the inter-relation between the object, ground, and camera. As a result, the reconstructed objects often appear floating or tilted when placed on flat surfaces. This limitation significantly affects 3D-aware image editing applications like shadow rendering and object pose manipulation. To address this issue, we introduce ORG (Object Reconstruction with Ground), a novel task aimed at reconstructing 3D object geometry in conjunction with the ground surface. Our method uses two compact pixel-level representations to depict the relationship between camera, object, and ground. Experiments show that the proposed ORG model can effectively reconstruct object-ground geometry on unseen data, significantly enhancing the quality of shadow generation and pose manipulation compared to conventional single-image 3D reconstruction techniques.



### ObjectCarver: Semi-automatic segmentation, reconstruction and separation of 3D objects
- **Arxiv ID**: http://arxiv.org/abs/2407.19108v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2407.19108v1)
- **Published**: 2024-07-26 22:13:20+00:00
- **Updated**: 2024-07-26 22:13:20+00:00
- **Authors**: Gemmechu Hassena, Jonathan Moon, Ryan Fujii, Andrew Yuen, Noah Snavely, Steve Marschner, Bharath Hariharan
- **Comment**: Project page is: https://objectcarver.github.io/
- **Journal**: None
- **Summary**: Implicit neural fields have made remarkable progress in reconstructing 3D surfaces from multiple images; however, they encounter challenges when it comes to separating individual objects within a scene. Previous work has attempted to tackle this problem by introducing a framework to train separate signed distance fields (SDFs) simultaneously for each of N objects and using a regularization term to prevent objects from overlapping. However, all of these methods require segmentation masks to be provided, which are not always readily available. We introduce our method, ObjectCarver, to tackle the problem of object separation from just click input in a single view. Given posed multi-view images and a set of user-input clicks to prompt segmentation of the individual objects, our method decomposes the scene into separate objects and reconstructs a high-quality 3D surface for each one. We introduce a loss function that prevents floaters and avoids inappropriate carving-out due to occlusion. In addition, we introduce a novel scene initialization method that significantly speeds up the process while preserving geometric details compared to previous approaches. Despite requiring neither ground truth masks nor monocular cues, our method outperforms baselines both qualitatively and quantitatively. In addition, we introduce a new benchmark dataset for evaluation.



